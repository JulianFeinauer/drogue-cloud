:icons: font

ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]

:toc:
:toc-placement!:

= Deploying

This guide should take your through the process of deploying the example.

NOTE: All commands are relative to the root of the repository.

'''

toc::[]

== Pre-requisites

The following pre-requisites are required to run this. As there are many ways to obtain them, I will stick to my
own environment, and try to point out possible differences.

Also, there may be newer versions of the components I used, maybe you can upgrade, maybe not.

=== Command line tools

The usual command line tools. I would like to call out the following:

* `kn` - The Knative command line tool. Not required, but might come in handy.
* `oc` / `kubectl` - In our case, there isn't a big difference. I try to go for `kubectl`, but should
you encounter `oc`, then just swap it. And/or raise a PR ðŸ˜‰
* `helm` - Used internall for pulling in some dependencies, get from https://github.com/helm/helm/releases[Helm releases]
* `http` - aka https://httpie.org/[HTTPie]
* `mqtt` - aka https://github.com/hivemq/mqtt-cli[MQTT CLI]
* `openssl` - to create a TLS Secret for the MQTT endpoint

=== Kubernetes

You will need an installation of Kubernetes. This should work on OpenShift, Minikube, Kind, and all other versions
of Kubernetes.

For the script we provide, we try to focus on Minikube, OpenShift, and Kind. However it should be possible
to re-use them for other Kubernetes types as well.

== Dependencies

On the cluster you will need some infrastructure components installed. By default the deployment scripts
will install dependencies, but there are other ways to install things as well. The following sub-sections
describe what is required.

NOTE: All following dependencies will be installed by the deployment scripts. There is no need to install
them manually, unless you explicitly wish to do so.

=== Strimzi

For Kafka, this deployment requires https://strimzi.io/[Strimzi]. I deployed "Strimzi" from OperatorHub.

=== Knative 0.17.x

On the cluster, you will need https://knative.dev/[Knative], including the following features:

* Serving
* Eventing
* Kafka event support

The easiest way is to get the https://operatorhub.io/operator/knative-operator[Knative operator],
through OperatorHub. Then install https://knative.dev/docs/install/knative-with-operators/#installing-the-knative-serving-component[serving and eventing].

I needed to add the Kafka eventing after that, I used the https://github.com/openshift-knative/knative-kafka-operator[knative kafka operator]. If you are using Openshift, you can follow https://openshift-knative.github.io/docs/docs/proc_apache-kafka.html[this guide].
Install the operator following these instructions, but don't create any CRfootnote:[custom resource] yet.

== Performing the deployment

Once you have all pre-requisites installed, you can start deploying.

Run the `./hack/drogue.sh` script and pass the Kubernetes type you use (`minikube` is the default):

----
env CLUSTER=minikube ./hack/drogue.sh
----

== Testing

The deployment script will print out the necessary connection information for your environment. It will
also suggest some commands to try out the installation.

You can get this information later on by running:

----
./hack/status.sh
----

The following sub-sections describe the examples in a bit more detail.

=== Console

You can open up the console to get some more information about the installation:

    https://console-drogue-iot.apps.my.cluster/

=== Dashboard

Login in to the Grafana instance and open the dashboard "Knative test". Double check it is set to
reload automatically.

=== Publish data using HTTP

==== Execute

From the command line run (and be sure to replace the URL with your own):

----
http POST https://http-endpoint-drogue-iot.apps.my.cluster/publish/device_id/foo temp:=2.5
----

==== Verify

The result should be something like:

----
HTTP/1.1 202 Accepted
content-length: 0
date: Fri, 11 Sep 2020 12:07:17 GMT
server: envoy
set-cookie: 84c0cd5758bb97f4b5bed57575911131=531e737940bb08052e1fa4cc58c12866; path=/; HttpOnly
x-envoy-upstream-service-time: 3616
----

If the content was accepted, it should pop up in the dashboard after a few seconds.

==== What just happened?!

* The data was published to the HTTP endpoint. Pre-processed and converted into a "cloud event",
* That cloud event was delivered to the Kafka channel, which stores it,
* The InfluxDB pusher got notified from the Kafka source (attached to the Kafka channel of the HTTP endpoint)â€¦
* â€¦ and writes it to the InfluxDB,
* From where the Grafana dashboard will poll it.

Like this:

.Overview diagram
image::../images/example.svg[Overview]

=== Publish data (MQTT)

==== Execute (MQTT v3.1.1)

From the command line run (and be sure to replace the host and port with your own):

----
mqtt pub -h mqtt-endpoint-drogue-iot.apps.my.cluster -p 443 -s -t temp -m '{"temp":33}' -V 3
----

==== Execute (MQTT v5)

From the command line run (and be sure to replace the host and port with your own):

----
mqtt pub -h mqtt-endpoint-drogue-iot.apps.my.cluster -p 443 -s -t temp -m '{"temp":33}'
----

==== Verify

In the output, you should see something like `received PUBLISH acknowledgement` as one of the
last messages. If the content was accepted, it should pop up in the dashboard after a few seconds.

==== What just happened?!

* The data was published to the MQTT endpoint. Pre-processed and converted into a "cloud event",
* That cloud event was delivered to the Kafka channel, which stores it,
* The InfluxDB pusher got notified from the Kafka source (attached to the Kafka channel of the HTTP endpoint)â€¦
* â€¦ and writes it to the InfluxDB,
* From where the Grafana dashboard will poll it.
